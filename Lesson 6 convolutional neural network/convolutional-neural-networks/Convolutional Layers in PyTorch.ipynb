{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Layers in PyTorch\n",
    "To create a convolutional layer in PyTorch, you must first import the necessary module:\n",
    "\n",
    "import torch.nn as nn\n",
    "Then, there is a two part process to defining a convolutional layer and defining the feedforward behavior of a model (how an input moves through the layers of a network). First, you must define a Model class and fill in two functions.\n",
    "\n",
    "init\n",
    "\n",
    "You can define a convolutional layer in the __init__ function of by using the following format:\n",
    "\n",
    "self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0)\n",
    "forward\n",
    "\n",
    "Then, you refer to that layer in the forward function! Here, I am passing in an input image x and applying a ReLU function to the output of this layer.\n",
    "\n",
    "x = F.relu(self.conv1(x))\n",
    "Arguments\n",
    "You must pass the following arguments:\n",
    "\n",
    "in_channels - The number of inputs (in depth), 3 for an RGB image, for example.\n",
    "out_channels - The number of output channels, i.e. the number of filtered \"images\" a convolutional layer is made of or the number of unique, convolutional kernels that will be applied to an input.\n",
    "kernel_size - Number specifying both the height and width of the (square) convolutional kernel.\n",
    "There are some additional, optional arguments that you might like to tune:\n",
    "\n",
    "stride - The stride of the convolution. If you don't specify anything, stride is set to 1.\n",
    "padding - The border of 0's around an input array. If you don't specify anything, padding is set to 0.\n",
    "NOTE: It is possible to represent both kernel_size and stride as either a number or a tuple.\n",
    "\n",
    "There are many other tunable arguments that you can set to change the behavior of your convolutional layers. To read more about these, we recommend perusing the official documentation.\n",
    "\n",
    "Pooling Layers\n",
    "Pooling layers take in a kernel_size and a stride. Typically the same value as is the down-sampling factor. For example, the following code will down-sample an input's x-y dimensions, by a factor of 2:\n",
    "\n",
    "self.pool = nn.MaxPool2d(2,2)\n",
    "forward\n",
    "\n",
    "Here, we see that poling layer being applied in the forward function.\n",
    "\n",
    "x = F.relu(self.conv1(x))\n",
    "x = self.pool(x)\n",
    "Convolutional Example #1\n",
    "Say I'm constructing a CNN, and my input layer accepts grayscale images that are 200 by 200 pixels (corresponding to a 3D array with height 200, width 200, and depth 1). Then, say I'd like the next layer to be a convolutional layer with 16 filters, each filter having a width and height of 2. When performing the convolution, I'd like the filter to jump two pixels at a time. I also don't want the filter to extend outside of the image boundaries; in other words, I don't want to pad the image with zeros. Then, to construct this convolutional layer, I would use the following line of code:\n",
    "\n",
    "self.conv1 = nn.Conv2d(1, 16, 2, stride=2)\n",
    "Convolutional Example #2\n",
    "Say I'd like the next layer in my CNN to be a convolutional layer that takes the layer constructed in Example 1 as input. Say I'd like my new layer to have 32 filters, each with a height and width of 3. When performing the convolution, I'd like the filter to jump 1 pixel at a time. I want this layer to have the same width and height as the input layer, and so I will pad accordingly. Then, to construct this convolutional layer, I would use the following line of code:\n",
    "\n",
    "self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "\n",
    "Convolution with 3x3 window and stride 1\n",
    "\n",
    "Image source: http://iamaaditya.github.io/2016/03/one-by-one-convolution/\n",
    "\n",
    "Sequential Models\n",
    "We can also create a CNN in PyTorch by using a Sequential wrapper in the __init__ function. Sequential allows us to stack different types of layers, specifying activation functions in between!\n",
    "\n",
    "def __init__(self):\n",
    "        super(ModelName, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "              nn.Conv2d(1, 16, 2, stride=2),\n",
    "              nn.MaxPool2d(2, 2),\n",
    "              nn.ReLU(True),\n",
    "\n",
    "              nn.Conv2d(16, 32, 3, padding=1),\n",
    "              nn.MaxPool2d(2, 2),\n",
    "              nn.ReLU(True) \n",
    "         )\n",
    "Formula: Number of Parameters in a Convolutional Layer\n",
    "The number of parameters in a convolutional layer depends on the supplied values of filters/out_channels, kernel_size, and input_shape. Let's define a few variables:\n",
    "\n",
    "K - the number of filters in the convolutional layer\n",
    "F - the height and width of the convolutional filters\n",
    "D_in - the depth of the previous layer\n",
    "Notice that K = out_channels, and F = kernel_size. Likewise, D_in is the last value in the input_shape tuple, typically 1 or 3 (RGB and grayscale, respectively).\n",
    "\n",
    "Since there are F*F*D_in weights per filter, and the convolutional layer is composed of K filters, the total number of weights in the convolutional layer is K*F*F*D_in. Since there is one bias term per filter, the convolutional layer has K biases. Thus, the number of parameters in the convolutional layer is given by K*F*F*D_in + K.\n",
    "\n",
    "Formula: Shape of a Convolutional Layer\n",
    "The shape of a convolutional layer depends on the supplied values of kernel_size, input_shape, padding, and stride. Let's define a few variables:\n",
    "\n",
    "K - the number of filters in the convolutional layer\n",
    "F - the height and width of the convolutional filters\n",
    "S - the stride of the convolution\n",
    "P - the padding\n",
    "W_in - the width/height (square) of the previous layer\n",
    "Notice that K = out_channels, F = kernel_size, and S = stride. Likewise, W_in is the first and second value of the input_shape tuple.\n",
    "\n",
    "The depth of the convolutional layer will always equal the number of filters K.\n",
    "\n",
    "The spatial dimensions of a convolutional layer can be calculated as: (W_inâˆ’F+2P)/S+1\n",
    "\n",
    "Flattening\n",
    "Part of completing a CNN architecture, is to flatten the eventual output of a series of convolutional and pooling layers, so that all parameters can be seen (as a vector) by a linear classification layer. At this step, it is imperative that you know exactly how many parameters are output by a layer.\n",
    "\n",
    "For the following quiz questions, consider an input image that is 130x130 (x, y) and 3 in depth (RGB). Say, this image goes through the following layers in order:\n",
    "\n",
    "nn.Conv2d(3, 10, 3)\n",
    "nn.MaxPool2d(4, 4)\n",
    "nn.Conv2d(10, 20, 5, padding=2)\n",
    "nn.MaxPool2d(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/python3\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Complete the compareTriplets function below.\n",
    "def compareTriplets(a, b):\n",
    "    for x in enumerate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b = 0,0\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "arr = [[11,2,4],[4,5,6],[10,8,-12]]\n",
    "sums = 0\n",
    "for x in range(n):\n",
    "    sums += arr[x][x]\n",
    "print(sums)\n",
    "for y in range(-n-1):\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/python3\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "\n",
    "#\n",
    "# Complete the 'diagonalDifference' function below.\n",
    "#\n",
    "# The function is expected to return an INTEGER.\n",
    "# The function accepts 2D_INTEGER_ARRAY arr as parameter.\n",
    "#\n",
    "\n",
    "def diagonalDifference(arr):\n",
    "    # Write your code here\n",
    "    #arr have list of lists\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fptr = open(os.environ['OUTPUT_PATH'], 'w')\n",
    "\n",
    "    n = int(input().strip())\n",
    "\n",
    "    arr = []\n",
    "\n",
    "    for _ in range(n):\n",
    "        arr.append(list(map(int, input().rstrip().split())))\n",
    "\n",
    "    result = diagonalDifference(arr)\n",
    "\n",
    "    fptr.write(str(result) + '\\n')\n",
    "\n",
    "    fptr.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "arr = [[11,2,4],[4,5,6],[10,8,-12]]\n",
    "sums = 0\n",
    "for x in range(n):\n",
    "    sums += arr[x][x]\n",
    "print(sums)\n",
    "for y in range(-(n-1)):\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
